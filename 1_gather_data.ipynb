{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee32860-1ea4-4daa-98fc-291749307fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52c8a0-b7be-4019-878a-4e9ac1ff4895",
   "metadata": {},
   "source": [
    "## HEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8b339-098d-4b27-89a0-8c1167b5ac8a",
   "metadata": {},
   "source": [
    "#### HEAD 01 - toggle user settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18e3fdb-3cd1-47ca-94c6-0544e31fe7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine whether to cache data from some time consuming tasks\n",
    "settings = {\n",
    "    'num_parallel_cores': 13,\n",
    "    'test_mode': False, ## when true, only a small of data is collected\n",
    "    \n",
    "    'collect_data': False, ## toggles twitter api pulls in PULL01-03\n",
    "    \n",
    "    'rebuild_word_data': False, ## rebuild vs cache load for word_data MUNG02\n",
    "    'rebuild_tweet_words': False, ## rebuild vs cache load tweet_words MUNG03\n",
    "    'rebuild_user_token': False, ## rebuild v cache load user_token_tally MUNG04\n",
    "    \n",
    "    'use_pca': False, ## use a pca simplification of the features matrix\n",
    "    \n",
    "    'redo_hparam_logistic': False, ## recalculate/cache TRAI03\n",
    "    'redo_hparam_naive_bayes': False, ## recalculate/cache TRAI04\n",
    "    'redo_hparam_random_forest': False, ## recalculate/cache TRAI05\n",
    "    'redo_hparam_adaboost': False ## recalculate/cache TRAI06\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16158d71-339e-4026-93e9-b270cc45859d",
   "metadata": {},
   "source": [
    "#### HEAD02 - load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0914f0c2-3000-4136-94e5-630181f3e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from time import sleep\n",
    "from os.path import exists\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18441e2b-97b6-4243-a468-0de4c7e31258",
   "metadata": {},
   "source": [
    "#### HEAD03 - load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f766755-c82c-49a1-ae9a-05155a84f8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s8/opt/anaconda3/envs/py310/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## read in roster of handles\n",
    "user_data = pd.read_excel(\"A_Input/twitter_handles.xlsx\")\n",
    "\n",
    "## drop all but a handful of cases if in test mode\n",
    "if settings['test_mode']:\n",
    "    user_data = user_data.sample(125, random_state = 5542)\n",
    "\n",
    "## read in twitter credentials; initialize api connection+\n",
    "twitter_credentials = pd.read_csv('../api_keys/twitter.csv').set_index('item')\n",
    "twitter_credentials = tweepy.OAuth1UserHandler(\n",
    "    consumer_key = twitter_credentials.loc['API Key', 'string'],\n",
    "    consumer_secret = twitter_credentials.loc['API Key Secret', 'string'],\n",
    "    access_token = twitter_credentials.loc['Access Token', 'string'],\n",
    "   access_token_secret = twitter_credentials.loc['Access Token Secret', 'string']\n",
    "    )\n",
    "api = tweepy.API(twitter_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934eace4-543f-4ff2-81cc-0eb3cc114c18",
   "metadata": {},
   "source": [
    "#### HEAD04 - create build or cache decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96445ddf-b3b5-4672-95d7-cc48563f54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build switching function to execute code or cache results\n",
    "def build_or_cache_csv(address, function, build_bool):\n",
    "    if build_bool or not exists(address):\n",
    "        x = function()\n",
    "        x.to_csv(address, index = False)\n",
    "        return x\n",
    "    else:\n",
    "        return pd.read_csv(address)\n",
    "    \n",
    "def build_or_cache_pickle(address, function, build_bool):\n",
    "    if build_bool or not exists(address):\n",
    "        x = function()\n",
    "        conn = open(address, 'wb')\n",
    "        pickle.dump(x, conn)\n",
    "        conn.close()\n",
    "        return x\n",
    "    else:\n",
    "        conn = open(address, 'rb')\n",
    "        x = pickle.load(conn)\n",
    "        conn.close()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fd8c1f-1a4e-4dca-a2de-100adffbceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed49a6b-8b72-4edd-84b8-0f815986fc01",
   "metadata": {},
   "source": [
    "## HAND – Gather Twitter handles for test accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67daeb1-100d-4fc1-9c20-f28ed2c1ec0a",
   "metadata": {},
   "source": [
    "#### HAND01 - extract handles from roster URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdda14bb-55b3-41d9-b735-b674367eee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract handles from roster urls\n",
    "user_data['handle'] = user_data.url.str.replace('https://twitter.com/', '',\n",
    "            regex = False).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db8ac6c-b02c-454a-ae37-cf1cc444b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e64b95-7e26-4789-b736-089706334fad",
   "metadata": {},
   "source": [
    "## PULL - Pull Twitter data from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9531973-8911-4beb-a48b-1c7989ae2428",
   "metadata": {},
   "source": [
    "#### PULL01 - query API for each roster handle's user_timeline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1200e6ca-cf86-412a-bdf2-da760105698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract tweet data from api object\n",
    "def refine_tweet_data(x):\n",
    "    tweet_data = list()\n",
    "    for i in range(0, len(x)):\n",
    "        tweet_data.append({\n",
    "            'tweet_id': x[i].id, \n",
    "            'created_at': x[i].created_at, \n",
    "            'lang': x[i].lang,\n",
    "            'full_text': x[i].full_text,\n",
    "            'screen_name': x[i].author.screen_name,\n",
    "            'verified' : x[i].author.verified\n",
    "        })\n",
    "    return pd.DataFrame(tweet_data)\n",
    "\n",
    "## define function to pull user tweet data and apply function to extract tweet data\n",
    "def pull_tweet_data(handles = user_data.handle, a = api):\n",
    "    tweet_data = list()\n",
    "    for i in handles:\n",
    "        try:\n",
    "            user_tweets = a.user_timeline(\n",
    "                screen_name = i, count = 200, tweet_mode = 'extended', \n",
    "                exclude_replies = True, include_rts = False)\n",
    "            tweet_data.append(refine_tweet_data(user_tweets))\n",
    "            sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "    tweet_data = pd.concat(tweet_data)\n",
    "    tweet_data['screen_name'] = tweet_data['screen_name'].str.lower()\n",
    "    return tweet_data\n",
    "\n",
    "## execute code\n",
    "if settings['collect_data']:\n",
    "    tweet_data = pull_tweet_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7301b7-3283-45c5-8943-1444d0e8cf27",
   "metadata": {},
   "source": [
    "#### PULL02 - tabulate tweet statistics, divide users into train/tune/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f26d7ac-312e-4445-a22a-0f8bada0d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combile tweet count and verification status at the user level\n",
    "def enhance_user_data(td, ud = user_data):\n",
    "    \n",
    "    def np_size(x): return x.size\n",
    "    \n",
    "    ## calculate tweet summary statistics\n",
    "    td_original = tweet_data\n",
    "    td = td.copy()\n",
    "    verified = td.groupby('screen_name').mean()\n",
    "    tweets = td['screen_name'].value_counts()\n",
    "    td = pd.concat([verified, tweets], axis = 1).reset_index()\n",
    "    td.columns = ['handle', 'verified', 'tweets']\n",
    "    \n",
    "    ## merge statistics into the user_data object\n",
    "    ud = pd.merge(ud, td, on = 'handle', how = 'left')\n",
    "    td_original = td_original.drop(['verified'], axis = 1)\n",
    "    ud = ud.drop(['url'], axis = 1).reset_index(drop = True)\n",
    "    ud = ud.fillna({'tweets': 0}).astype({'tweets': int})\n",
    "    \n",
    "    ## divide users into train, and test subsets\n",
    "    ml_set = pd.Series(['train', 'test'], name = 'ml_set').sample(\n",
    "                n = ud.shape[0], replace = True, weights = [0.8, 0.20],\n",
    "                random_state = 2006)\n",
    "    ud['ml_set'] = ml_set.values\n",
    "    ud.loc[ud.tweets == 0, 'ml_set'] = 'exclude'\n",
    "    \n",
    "    return ud, td_original\n",
    "\n",
    "## execute code\n",
    "if settings['collect_data']:\n",
    "    user_data, tweet_data = enhance_user_data(\n",
    "        tweet_data[['screen_name', 'verified']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6e488-00b0-4257-a07b-598824c2aa18",
   "metadata": {},
   "source": [
    "#### PULL03 - save datasets to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb27d14-f5e0-40ef-beac-2f6d369a9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save user/tweet datasets to disk as csvs\n",
    "if settings['collect_data']:\n",
    "    user_data.to_csv('B_Process/user_data.csv', index = False)\n",
    "    tweet_data.to_csv('B_Process/tweet_data.csv', index = False)\n",
    "else:\n",
    "    user_data = pd.read_csv('B_Process/user_data.csv')\n",
    "    tweet_data = pd.read_csv('B_Process/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab22ae2d-8e04-4fa8-91de-70498694d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1152f-f55d-4758-a9d1-78e30499f55f",
   "metadata": {},
   "source": [
    "## MUNG - Process Twitter data to model-ready format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fdb93-7acf-43e0-9ae9-3ae2eb6a749e",
   "metadata": {},
   "source": [
    "#### MUNG01 - parse tweet text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3362904b-047d-44ef-9497-12af5a5421ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenize, remove capitalization, and remove duplicate tokens\n",
    "def nlp_tokenize_tweet(x):\n",
    "    x = x.lower()\n",
    "    x = word_tokenize(x)\n",
    "    x = list(set(x))\n",
    "    return x\n",
    "\n",
    "## execute code\n",
    "tweet_data['tokens'] = tweet_data.full_text.apply(nlp_tokenize_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422810c-53d2-4b5e-b9e8-68457e82756b",
   "metadata": {},
   "source": [
    "#### MUNG02 - create word/token level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f7a6af-6786-469b-8ec6-f07fb6d31709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/rmkl6dh17jl6zqhzl0ky4b_w0000gp/T/ipykernel_17766/3614223863.py:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(address)\n"
     ]
    }
   ],
   "source": [
    "## create word/token level dataset and identify valid word tokens\n",
    "def make_word_data(td = tweet_data):\n",
    "\n",
    "    ## flatten token lists and count occurances\n",
    "    word_data = list()\n",
    "    for i in td.tokens:\n",
    "        word_data += i\n",
    "    word_data = pd.Series(word_data, name = 'count').value_counts()\n",
    "    word_data = word_data.sort_values(ascending = False)\n",
    "    word_data = pd.DataFrame(word_data)\n",
    "    \n",
    "    ## determine which tokens occur often enough to warrant inclusion\n",
    "    word_data['valid'] = word_data['count'] > max(\n",
    "        word_data['count'].quantile(0.2), 3)\n",
    "    word_data['word'] = word_data.index\n",
    "    \n",
    "    ## determine part of speech for eligible tokens\n",
    "    speech_part = word_data['word'].loc[word_data['valid']].values\n",
    "    speech_part = pos_tag(speech_part)\n",
    "    speech_part = [i[1][0].lower() for i in speech_part]\n",
    "    word_data['pos'] = '.'\n",
    "    word_data.loc[word_data['valid'], 'pos'] = speech_part\n",
    "    \n",
    "    ## lemmatize\n",
    "    WNL = WordNetLemmatizer()\n",
    "    word_data['token'] = None\n",
    "    for i in word_data.word:\n",
    "        if not word_data.loc[i, 'valid']: \n",
    "            break\n",
    "        if word_data.loc[i, 'pos'] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            try:\n",
    "                word_data.loc[i, 'token'] = WNL.lemmatize(\n",
    "                    word_data.loc[i, 'word'],\n",
    "                    pos = word_data.loc[i, 'pos']\n",
    "                )\n",
    "            except:\n",
    "                word_data.loc[i, 'token'] = word_data.loc[i, 'word']\n",
    "        else:\n",
    "            word_data.loc[i, 'valid'] = False\n",
    "        \n",
    "    return word_data.reset_index(drop = True)\n",
    "\n",
    "## execute code\n",
    "word_data = build_or_cache_csv(\n",
    "    address = 'B_Process/word_data.csv',\n",
    "    function = make_word_data,\n",
    "    build_bool = settings['rebuild_word_data']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419c4d1-dada-48f5-9bcd-252137c407b5",
   "metadata": {},
   "source": [
    "#### MUNG03 - generate a tokens x tweets link database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247437d5-61e4-4143-93b2-cc66edf8b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tweet_token_data(td = tweet_data, wd = word_data):\n",
    "    \n",
    "    wd = wd.set_index('word')\n",
    "    \n",
    "    ## replicate tweet ids\n",
    "    n = td.tokens.apply(len).values\n",
    "    tweet_tokens = pd.Series(np.repeat(td.tweet_id.values, n), name = \"tweet_id\")\n",
    "    tweet_tokens = pd.DataFrame(tweet_tokens)\n",
    "    \n",
    "    ## allocate words to the new dataset\n",
    "    words = list()\n",
    "    for i in td.tokens:\n",
    "        words += i\n",
    "    tweet_tokens['words'] = words\n",
    "    \n",
    "    ## convert words to tokens\n",
    "    tweet_tokens['tokens'] = wd.loc[\n",
    "        tweet_tokens.words.values, 'token'].values\n",
    "    tweet_tokens = tweet_tokens.dropna()\n",
    "\n",
    "    return tweet_tokens.reset_index(drop = True)\n",
    "\n",
    "## execute code\n",
    "tweet_words = build_or_cache_csv(\n",
    "    address = 'B_Process/tweet_words.csv',\n",
    "    function = make_tweet_token_data,\n",
    "    build_bool = settings['rebuild_tweet_words']\n",
    "    )\n",
    "tweet_data = tweet_data.drop('tokens', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5cef3-bc88-4f27-9a5e-f76ce06d149c",
   "metadata": {},
   "source": [
    "#### MUNG04 - generate a tokens x users count; drop tokens with only one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc82f94-94cf-4030-a5d9-b3f5e5bbd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_token_matrix(td = tweet_data, tw = tweet_words, ud = user_data):\n",
    "    \n",
    "    ## count of number of times each user wrote each token\n",
    "    tw = tw.merge(right = td[['screen_name', 'tweet_id']],\n",
    "                  how = 'left', on = 'tweet_id')\n",
    "    tw = tw.drop(['tweet_id', 'words'], axis = 1).groupby('screen_name')\n",
    "    tw = tw.value_counts()\n",
    "    tw.name = 'count'\n",
    "    tw = tw.reset_index().set_index('screen_name')\n",
    "    tw = tw.pivot(columns = 'tokens').fillna(0).astype(int)\n",
    "    tw = tw.droplevel(axis = 1, level = 0)\n",
    "    \n",
    "    ## remove tokens that fewer than 3 or more than 80 percent of users use\n",
    "    valid_usage = (tw > 0).astype(int).sum().values\n",
    "    valid_usage = (valid_usage > 2\n",
    "                  ) & (valid_usage < int(tw.shape[0] * 0.8))\n",
    "    tw = tw.loc[:, valid_usage]\n",
    "    \n",
    "    ## standardize matrix as words per 1,000 tweets\n",
    "    denom = pd.DataFrame({'handle': tw.index}).merge(\n",
    "        ud[['handle', 'tweets']],\n",
    "        how = 'left', on = 'handle'\n",
    "        ).set_index('handle').squeeze().fillna(1)\n",
    "    denom.loc[denom < 1] = 1\n",
    "    tw = (tw.divide(denom, axis = 0) * 1000).astype(int)\n",
    "    tw = tw.reset_index().rename({'level_0':'screen_name'}, axis = 1)\n",
    "    \n",
    "    return tw\n",
    "\n",
    "\n",
    "## execute code\n",
    "user_token_matrix = build_or_cache_csv(\n",
    "    address = 'B_Process/user_token_matrix.csv',\n",
    "    function = make_user_token_matrix,\n",
    "    build_bool = settings['rebuild_user_token']\n",
    "    ).set_index('screen_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2591e88-3b00-4e6a-a199-bb129120db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0ad36-2fff-4c0f-8b41-a0dba7c3d20a",
   "metadata": {},
   "source": [
    "## TRAI – Train models and tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db026d-6e08-43d1-9c7e-7d49128c501f",
   "metadata": {},
   "source": [
    "#### TRAI00 - Unpack train, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54825b0-26cd-4d7a-81eb-fb77f4c5b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unpack train and test datasets\n",
    "def split_xy_data(ml_cat):\n",
    "    i = user_data.loc[user_data.ml_set == ml_cat, 'handle'].values\n",
    "    \n",
    "    x = user_token_matrix.loc[i, :]\n",
    "    \n",
    "    y1 = user_data.set_index('handle').loc[i, 'group'] == 'USA House'\n",
    "    y1 = y1.astype(int)\n",
    "    \n",
    "    y2 = user_data.set_index('handle').loc[i, 'party'] == 'Republican'\n",
    "    y2 = y2.astype(int)\n",
    "    \n",
    "    return x, y1, y2\n",
    "\n",
    "## execute code\n",
    "train_x, train_y1, train_y2 = split_xy_data('train')\n",
    "test_x, test_y1, test_y2    = split_xy_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09e904b6-a715-42d7-92c3-1457065b62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete objects to clear up memory in prep for modeling\n",
    "del tweet_words, tweet_data, user_token_matrix, word_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468fe729-41ac-4f57-9eb5-a9d62004211a",
   "metadata": {},
   "source": [
    "#### TRAI01 - generate PCA simplification of features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c526bae5-a1f2-4daf-b566-ef88d384aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit pca model in order to simplify and enhance feature matrix\n",
    "model_pca = PCA().fit(train_x)\n",
    "\n",
    "## generate pca transformations of all feature matrices\n",
    "train_x_pca = model_pca.transform(train_x)\n",
    "test_x_pca  = model_pca.transform(test_x)\n",
    "\n",
    "if settings['use_pca']:\n",
    "    train_x = train_x_pca\n",
    "    test_x  = test_x_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84d1f6-9a64-49aa-a13a-64af0205b4df",
   "metadata": {},
   "source": [
    "#### TRAI02 - estimate model performance at random chance (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91ed92b5-d95e-4a6e-b55f-473d2f2b36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimate the confusion matrix that would result by random chance\n",
    "   ## if we predicted labels based on frequently in the training set.\n",
    "   ## This function predicts results for a single stage.\n",
    "def estimate_random_confusion_matrix(y1, y2):\n",
    "    \n",
    "    ## tabulate probability of a positive at random\n",
    "    pos1  = y1.mean()\n",
    "    pos2  = y2.mean()\n",
    "    \n",
    "    ## calculate confusion matrix stats\n",
    "    confusion_matrix = {\n",
    "        'neg': {\n",
    "            'neg': (1 - pos1) * (1 - pos2),\n",
    "            'pos': (1 - pos1) * pos2\n",
    "            },\n",
    "        'pos': {\n",
    "            'neg': pos1 * (1 - pos2),\n",
    "            'pos': pos1 * pos2\n",
    "\n",
    "            }\n",
    "        }\n",
    "    confusion_matrix = pd.DataFrame(confusion_matrix)\n",
    "    \n",
    "    ## check results and return\n",
    "    assert confusion_matrix.sum().sum() == 1\n",
    "    return confusion_matrix\n",
    "\n",
    "## generate the joint confusion matrix for a multi-stage random chance model\n",
    "def estimate_multistage_random_confusion_matrix(y1p, y1o, y2p, y2o, name):\n",
    "    \n",
    "    ## generate confusion matrix for each stage\n",
    "    stage1 = estimate_random_confusion_matrix(y1p, y1o)\n",
    "    stage2 = estimate_random_confusion_matrix(y2p, y2o)\n",
    "    \n",
    "    ## generate confusion matrix for both stages combined\n",
    "    joint_matrix = stage1 * 0\n",
    "    joint_matrix.loc['pos', 'pos'] = stage1.loc['pos', 'pos'] *\\\n",
    "                                    stage2.loc['pos', 'pos']\n",
    "    joint_matrix.loc['pos', 'neg'] = stage1.loc['pos', 'neg'] *\\\n",
    "                                    stage2.loc['pos', 'neg'] +\\\n",
    "                                    stage1.loc['pos', 'neg'] *\\\n",
    "                                    stage2.loc['pos', 'pos'] +\\\n",
    "                                    stage1.loc['pos', 'pos'] *\\\n",
    "                                    stage2.loc['pos', 'neg']\n",
    "    joint_matrix.loc['neg', 'pos'] = stage1.loc['neg', 'pos'] *\\\n",
    "                                    stage2.loc['neg', 'pos'] +\\\n",
    "                                    stage1.loc['neg', 'pos'] *\\\n",
    "                                    stage2.loc['pos', 'pos'] +\\\n",
    "                                    stage1.loc['pos', 'pos'] *\\\n",
    "                                    stage2.loc['neg', 'pos']\n",
    "    joint_matrix.loc['neg', 'neg'] = 1 - joint_matrix.sum().sum()\n",
    "    \n",
    "    ## calculate precision and recall\n",
    "    performance = dict()\n",
    "    performance['Precision'] = joint_matrix.loc['pos', 'pos'] / (\n",
    "        joint_matrix.loc['pos', 'pos'] + joint_matrix.loc['pos', 'neg'])\n",
    "    performance['Recall'] = joint_matrix.loc['pos', 'pos'] / (\n",
    "        joint_matrix.loc['pos', 'pos'] + joint_matrix.loc['neg', 'pos'])\n",
    "    performance = pd.DataFrame({name: performance}).T.round(3)\n",
    "    \n",
    "    return performance\n",
    "\n",
    "## execute code (and create performance statistics container object)\n",
    "performance_stats = list()\n",
    "performance_stats.append(estimate_multistage_random_confusion_matrix(\n",
    "    train_y1, train_y1, train_y2, train_y2, ('random', 'train')))\n",
    "performance_stats.append(estimate_multistage_random_confusion_matrix(\n",
    "    train_y1, test_y1, train_y2, test_y2, ('random', 'test')))\n",
    "performance_stats = pd.concat(performance_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aee504-f3a0-413f-bccf-3be12edf1ceb",
   "metadata": {},
   "source": [
    "#### TRAI03 - Build a two-stage logistic model using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59295237-9c8a-49cd-8772-b5af8a1495be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract performance statistics from cross-validation\n",
    "def capture_generic_cv_stats(cv_results, param_list):\n",
    "    param_list = ['param_' + x for x in param_list]\n",
    "    i = ['mean_fit_time', 'mean_test_score'] + param_list\n",
    "    statistics = [cv_results[ii] for ii in i]\n",
    "    statistics = pd.DataFrame(statistics)\n",
    "    statistics.index = i\n",
    "    return statistics\n",
    "\n",
    "## use grid search with 5-fold cross-validation to find best hyperparameters\n",
    "   ## note: deliberately keeping the_model out of find_generic_hparams arg list\n",
    "   ## to prevent function from using a frozen snapsnot of the object\n",
    "the_model = GridSearchCV( \n",
    "    estimator = LogisticRegression(penalty = 'l1',\n",
    "                                   class_weight = 'balanced',\n",
    "                                   solver = 'saga',\n",
    "                                   max_iter = 2**10\n",
    "                                  ),\n",
    "    cv = 5, \n",
    "    n_jobs = settings['num_parallel_cores'], \n",
    "    param_grid = {'C': [2. ** i for i in range(-2, 6)]}\n",
    ")\n",
    "\n",
    "def find_generic_hparams(x = train_x, y1 = train_y1, y2 = train_y2):\n",
    "    ## fit models\n",
    "    model1 = the_model.fit(X = train_x, y = train_y1)\n",
    "    model2 = the_model.fit(X = train_x, y = train_y2, sample_weight = train_y1)\n",
    "    \n",
    "    ## return best fit hyperparameters\n",
    "    hyperparameters = pd.DataFrame({'model1': model1.best_params_,\n",
    "                                    'model2':model2.best_params_})\n",
    "    hparms = {\n",
    "        'hparam': hyperparameters,\n",
    "        'fit1': capture_generic_cv_stats(\n",
    "            model1.cv_results_, list(hyperparameters.index)),\n",
    "        'fit2': capture_generic_cv_stats(\n",
    "            model2.cv_results_, list(hyperparameters.index)),\n",
    "        }\n",
    "    for i in hyperparameters.index:\n",
    "        hparms[i] = hyperparameters.loc[i, :].values\n",
    "    return hparms\n",
    "\n",
    "## execute code  logistic_hyperparameters = find_logistic_hparams()\n",
    "logistic_hyperparameters = build_or_cache_pickle(\n",
    "    address = 'B_Process/logistic_hyperparameters.pickle',\n",
    "    function = find_generic_hparams,\n",
    "    build_bool = settings['redo_hparam_logistic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1aec1b6-970e-4aac-bacc-af675bac99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s8/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/s8/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## train model using the best hyperparameters\n",
    "def train_logistic_models(x = train_x, y1 = train_y1, y2 = train_y2, C = [1, 1]):\n",
    "    \n",
    "    ## formulate models\n",
    "    model1 = LogisticRegression(penalty = 'l1', class_weight = 'balanced',\n",
    "                               solver = 'saga', max_iter = 1e3, C = C[0])\n",
    "    model2 = LogisticRegression(penalty = 'l1', class_weight = 'balanced',\n",
    "                               solver = 'saga', max_iter = 1e3, C = C[1])\n",
    "    ## fit models\n",
    "    model1 = model1.fit(X = train_x, y = train_y1)\n",
    "    model2 = model2.fit(X = train_x, y = train_y2, sample_weight = train_y1)\n",
    "    \n",
    "    ## return models\n",
    "    return model1, model2\n",
    "\n",
    "## execute code\n",
    "logistic_models = train_logistic_models(C = logistic_hyperparameters['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46c40f56-965f-42d9-8794-88b590facb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate model performance the training and testing datasets\n",
    "def evaluate_generic_model(mod, name, tr_x = train_x, tr_y2 = train_y2,\n",
    "                           te_x = test_x, te_y2 = test_y2):\n",
    "    \n",
    "    ## predict values on training and testing sets\n",
    "    prediction = {\n",
    "        'train': mod[0].predict(tr_x) * mod[1].predict(tr_x),\n",
    "        'test':  mod[0].predict(te_x) * mod[1].predict(te_x)\n",
    "        }\n",
    "    \n",
    "    ## score predictions\n",
    "    performance = {\n",
    "        (name, 'train'): {\n",
    "            'Precision': precision_score(\n",
    "                            y_true = train_y2, y_pred = prediction['train']), \n",
    "            'Recall': recall_score(\n",
    "                            y_true = train_y2, y_pred = prediction['train']),\n",
    "            'F1': f1_score(\n",
    "                            y_true = train_y2, y_pred = prediction['train'])\n",
    "            },\n",
    "        (name, 'test'):  {\n",
    "            'Precision': precision_score(\n",
    "                            y_true = test_y2, y_pred = prediction['test']), \n",
    "            'Recall': recall_score(\n",
    "                            y_true = test_y2, y_pred = prediction['test']),\n",
    "            'F1': f1_score(\n",
    "                            y_true = test_y2, y_pred = prediction['test'])\n",
    "            }\n",
    "        }\n",
    "    performance = pd.DataFrame(performance).round(3).T\n",
    "    \n",
    "    return performance\n",
    "\n",
    "## execute code\n",
    "logistic_performance = evaluate_generic_model(logistic_models, 'logistic')\n",
    "performance_stats = pd.concat([logistic_performance,performance_stats], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e02f2-7778-461f-adeb-87ebdc540a84",
   "metadata": {},
   "source": [
    "#### TRAI04 - Build a two-stage naive bayes model using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f96d7a47-0667-4350-a6ac-210c14574408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the new model\n",
    "the_model = GridSearchCV( \n",
    "    estimator = GaussianNB(),\n",
    "    cv = 5, \n",
    "    n_jobs = settings['num_parallel_cores'], \n",
    "    param_grid = {'priors': [\n",
    "        (0.5, 0.5), \n",
    "        (1 - train_y1.mean(), train_y1.mean()),\n",
    "        (1 - train_y2.mean(), train_y2.mean()),\n",
    "    ]}\n",
    ")\n",
    "\n",
    "## define new training function\n",
    "def train_naive_bayes_models(priors,\n",
    "    x = train_x, y1 = train_y1, y2 = train_y2):\n",
    "    \n",
    "    ## formulate models\n",
    "    model1 = GaussianNB(priors = priors[0])\n",
    "    model2 = GaussianNB(priors = priors[1])\n",
    "\n",
    "    ## fit models\n",
    "    model1 = model1.fit(X = train_x, y = train_y1)\n",
    "    model2 = model2.fit(X = train_x, y = train_y2, sample_weight = train_y1)\n",
    "    \n",
    "    ## return models\n",
    "    return model1, model2\n",
    "\n",
    "## execute modeling code, recycling as much as possible from logistic\n",
    "naive_bayes_hyperparameters = build_or_cache_pickle(\n",
    "    address = 'B_Process/naive_bayes_hyperparameters.pickle',\n",
    "    function = find_generic_hparams,\n",
    "    build_bool = settings['redo_hparam_naive_bayes']\n",
    ")\n",
    "naive_bayes_models = train_naive_bayes_models(\n",
    "    priors = naive_bayes_hyperparameters['priors'])\n",
    "naive_bayes_performance = evaluate_generic_model(\n",
    "    naive_bayes_models, 'naive_bayes')\n",
    "performance_stats = pd.concat(\n",
    "    [naive_bayes_performance, performance_stats], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3cb043-f8c8-4e20-8545-d4db3470adda",
   "metadata": {},
   "source": [
    "#### TRAI05 - build a two-stage random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e98bdbdf-eea9-4313-b563-e553ed7d01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the new model\n",
    "the_model = GridSearchCV( \n",
    "    estimator = RandomForestClassifier(class_weight = 'balanced'),\n",
    "    cv = 5, \n",
    "    n_jobs = settings['num_parallel_cores'], \n",
    "    param_grid = {\n",
    "        'n_estimators': [2**i for i in range(6, 10)],\n",
    "        'min_samples_leaf': [2**i for i in range(2, 5)]\n",
    "    }\n",
    ")\n",
    "\n",
    "## define new training function\n",
    "def train_random_forest_models(n_estimators,  min_samples_leaf,\n",
    "    x = train_x, y1 = train_y1, y2 = train_y2):\n",
    "    \n",
    "    ## formulate models\n",
    "    model1 = RandomForestClassifier(\n",
    "        n_estimators = n_estimators[0],\n",
    "        min_samples_leaf = min_samples_leaf[0]\n",
    "    )\n",
    "    model2 = RandomForestClassifier(\n",
    "        n_estimators = n_estimators[1],\n",
    "        min_samples_leaf = min_samples_leaf[1]\n",
    "    )\n",
    "\n",
    "    ## fit models\n",
    "    model1 = model1.fit(X = train_x, y = train_y1)\n",
    "    model2 = model2.fit(X = train_x, y = train_y2, sample_weight = train_y1)\n",
    "    \n",
    "    ## return models\n",
    "    return model1, model2\n",
    "\n",
    "## execute modeling code, recycling as much as possible from logistic\n",
    "random_forest_hyperparameters = build_or_cache_pickle(\n",
    "    address = 'B_Process/random_forest_hyperparameters.pickle',\n",
    "    function = find_generic_hparams,\n",
    "    build_bool = settings['redo_hparam_random_forest']\n",
    ")\n",
    "random_forest_models = train_random_forest_models(\n",
    "    n_estimators = random_forest_hyperparameters['n_estimators'],\n",
    "    min_samples_leaf = random_forest_hyperparameters['min_samples_leaf']\n",
    ")\n",
    "random_forest_performance = evaluate_generic_model(\n",
    "    random_forest_models, 'random_forest')\n",
    "performance_stats = pd.concat(\n",
    "    [random_forest_performance, performance_stats], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778f074-563c-4f0d-ba09-38f3e935ee6d",
   "metadata": {},
   "source": [
    "#### TRAI06 - build a two-stage AdaBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c31af321-230c-49be-bc45-8457a8737217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the new model\n",
    "the_model = GridSearchCV( \n",
    "    estimator = AdaBoostClassifier(base_estimator = None),\n",
    "    cv = 5, \n",
    "    n_jobs = settings['num_parallel_cores'], \n",
    "    param_grid = {\n",
    "        'n_estimators':  [int(2**i) for i in range(6, 10)],\n",
    "        'learning_rate': [2**i for i in range(-2, 3)]\n",
    "    }\n",
    ")\n",
    "\n",
    "## define new training function\n",
    "def train_adaboost_models(n_estimators, learning_rate,\n",
    "    x = train_x, y1 = train_y1, y2 = train_y2):\n",
    "    \n",
    "    ## formulate models\n",
    "    model1 = AdaBoostClassifier(\n",
    "        n_estimators = n_estimators[0],\n",
    "        learning_rate = learning_rate[0]\n",
    "    )\n",
    "    model2 = AdaBoostClassifier(\n",
    "        n_estimators = n_estimators[1],\n",
    "        learning_rate = learning_rate[1]\n",
    "    )\n",
    "\n",
    "    ## fit models\n",
    "    model1 = model1.fit(X = train_x, y = train_y1)\n",
    "    model2 = model2.fit(X = train_x, y = train_y2, sample_weight = train_y1)\n",
    "    \n",
    "    ## return models\n",
    "    return model1, model2\n",
    "\n",
    "## execute modeling code, recycling as much as possible from logistic\n",
    "adaboost_hyperparameters = build_or_cache_pickle(\n",
    "    address = 'B_Process/adaboost_hyperparameters.pickle',\n",
    "    function = find_generic_hparams,\n",
    "    build_bool = settings['redo_hparam_adaboost']\n",
    ")\n",
    "adaboost_models = train_adaboost_models(\n",
    "    n_estimators = adaboost_hyperparameters['n_estimators'].astype(int),\n",
    "    learning_rate = adaboost_hyperparameters['learning_rate']\n",
    ")\n",
    "adaboost_performance = evaluate_generic_model(\n",
    "    adaboost_models, 'adaboost')\n",
    "performance_stats = pd.concat(\n",
    "    [adaboost_performance, performance_stats], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941865c-a26d-433d-94c3-48be742b4ceb",
   "metadata": {},
   "source": [
    "#### TRAI07 - save performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b437b8a-9c43-44bf-bf85-90b8b6a607af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save performance results to disk\n",
    "addr = 'B_Process/performance_stats{0}.csv'\n",
    "if settings['use_pca']: addr = addr.format('_pca')\n",
    "else: addr = addr.format('')\n",
    "performance_stats.to_csv(addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da37d27-4896-4ea9-b767-b80622cd95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TODO: Add prediction runtimes to hyperparameters, add f1 to random model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64189160-c590-484d-b783-02e4a1ba21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f9ec1b-cea5-4168-9a5e-d4767a436101",
   "metadata": {},
   "source": [
    "## FOOT - display useful statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e42c2cff-5e9c-46ac-84c5-367e8570889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train      646\n",
       "test       139\n",
       "exclude     11\n",
       "Name: ml_set, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.ml_set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d973309-e9bd-459c-a036-6bd65ddbf3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">adaboost</th>\n",
       "      <th>train</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">random_forest</th>\n",
       "      <th>train</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">naive_bayes</th>\n",
       "      <th>train</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">logistic</th>\n",
       "      <th>train</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">random</th>\n",
       "      <th>train</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.156</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Precision  Recall     F1\n",
       "adaboost      train      1.000   0.821  0.902\n",
       "              test       0.971   0.791  0.872\n",
       "random_forest train      1.000   0.858  0.923\n",
       "              test       0.976   0.930  0.952\n",
       "naive_bayes   train      1.000   0.826  0.905\n",
       "              test       0.944   0.791  0.861\n",
       "logistic      train      1.000   0.821  0.902\n",
       "              test       0.946   0.814  0.875\n",
       "random        train      0.191   0.191    NaN\n",
       "              test       0.191   0.156    NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f0eb3-aeb6-4048-99ad-1cf67b79861d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
